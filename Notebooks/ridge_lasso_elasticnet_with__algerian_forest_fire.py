# -*- coding: utf-8 -*-
"""Ridge_Lasso_ElasticNet_with _Algerian_Forest_Fire.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18x57NUywDW2AS6PLh7rfw3ewIwhGQ9ca
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df=pd.read_csv("/content/Algerian_forest_fires_dataset_UPDATE.csv",header=1)
df.head()

"""###Create Regression algorithm and predict temperature"""

df.info()

df.describe()

"""##DATA CLEANING"""

## missing values
df[df.isnull().any(axis=1)]

"""###The dataset is converted into two sets based on Region from 122th index, we can make a new column based on the Region

1 : "Bejaia Region Dataset"

2 : "Sidi-Bel Abbes Region Dataset"

Add new column with region
"""

df.loc[:122,"Region"]=0
df.loc[122:,"Region"]=1

df.info()

df[['Region']]=df[['Region']].astype(int)
df.head()

df.isnull().sum()

## Removing the null values
df=df.dropna().reset_index(drop=True)

df.iloc[[122]]

##remove the 122nd row
df=df.drop(122).reset_index(drop=True)

df.iloc[[122]]

df.columns

## fix spaces in columns names
df.columns=df.columns.str.strip()
df.columns

df.info()

df[['month','day','year','Temperature','RH','Ws']]=df[['month','day','year','Temperature','RH','Ws']].astype(int)

df.info()

df.head()

"""#### Changing the other columns to float data datatype

"""

objects=[features for features in df.columns if df[features].dtypes=='O']
objects

for i in objects:
    if i!='Classes':
        df[i]=df[i].astype(float)

df.info()

## Let save the cleaned dataset
df.to_csv('Algerian_forest_fires_cleaned_dataset.csv',index=False)

"""# **EDA**"""

## drop day,month and year
df_copy=df.drop(['day','month','year'],axis=1)

df_copy.head()

## categories in classes
df_copy['Classes'].value_counts()

## Encoding of the categories in classes
df_copy['Classes']=np.where(df_copy['Classes'].str.contains('not fire'),0,1)

df_copy.tail()

df_copy['Classes'].value_counts()

## Plot desnity plot for all features
plt.style.use('seaborn')
df_copy.hist(bins=50,figsize=(20,15))
plt.show()

## Percentage for Pie Chart
percentage=df_copy['Classes'].value_counts(normalize=True)*100

# plotting piechart
classlabels=["Fire","Not Fire"]
plt.figure(figsize=(12,7))
plt.pie(percentage,labels=classlabels,autopct='%1.1f%%')
plt.title("Pie Chart of Classes")
plt.show()

"""#**Correlation**"""

df_copy.corr()

sns.heatmap(df.corr(),annot=True)

## Box Plots
sns.boxplot(df['FWI'],color='green')

df.head()

df['Classes']=np.where(df['Classes'].str.contains('not fire'),'not fire','fire')

## Monthly Fire Analysis
dftemp=df.loc[df['Region']==1]
plt.subplots(figsize=(13,6))
sns.set_style('whitegrid')
sns.countplot(x='month',hue='Classes',data=df)
plt.ylabel('Number of Fires',weight='bold')
plt.xlabel('Months',weight='bold')
plt.title("Fire Analysis of Sidi- Bel Regions",weight='bold')

"""##**MODEL TRAINING**"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df=pd.read_csv("/content/Algerian_forest_fires_cleaned_dataset.csv")
df

df.head()

df.columns

df.drop(['day', 'month', 'year'],axis=1,inplace=True)

df.head()

df["Classes"].value_counts()

## Encoding
df['Classes']=np.where(df['Classes'].str.contains('not fire'),0,1)
##This will encode not fire=0 and fire=0

df.head()

## Independent And dependent features
X=df.drop('FWI',axis=1)
y=df['FWI']

X.head()

#Train Test Split
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=42)

X_train.shape,X_test.shape

## Feature Selection based on correlaltion
X_train.corr()

## Check for multicollinearity
plt.figure(figsize=(12,10))
corr=X_train.corr()
sns.heatmap(corr,annot=True)

X_train.corr()

def correlation(dataset, threshold):
    col_corr = set()
    corr_matrix = dataset.corr()
    for i in range(len(corr_matrix.columns)):
        for j in range(i):
            if abs(corr_matrix.iloc[i, j]) > threshold: 
                colname = corr_matrix.columns[i]
                col_corr.add(colname)
    return col_corr

## threshold--Domain expertise
corr_features=correlation(X_train,0.85)

corr_features

## drop features when correlation is more than 0.85 
X_train.drop(corr_features,axis=1,inplace=True)
X_test.drop(corr_features,axis=1,inplace=True)
X_train.shape,X_test.shape

"""#**FEATURE SCALLING AND STANDARIZATION**"""

from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()
X_train_scaled=scaler.fit_transform(X_train)
X_test_scaled=scaler.transform(X_test)

X_train_scaled

"""##Box Plots To understand Effect Of Standard Scaler"""

plt.subplots(figsize=(15, 5))
plt.subplot(1, 2, 1)
sns.boxplot(data=X_train)
plt.title('X_train Before Scaling')
plt.subplot(1, 2, 2)
sns.boxplot(data=X_train_scaled)
plt.title('X_train After Scaling')

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import r2_score
linreg=LinearRegression()
linreg.fit(X_train_scaled,y_train)
y_pred=linreg.predict(X_test_scaled)
mae=mean_absolute_error(y_test,y_pred)
score=r2_score(y_test,y_pred)
print("Mean absolute error", mae)
print("R2 Score", score)
plt.scatter(y_test,y_pred)

"""##**Lasso_Reg**##"""

from sklearn.linear_model import Lasso
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import r2_score
lasso=Lasso()
lasso.fit(X_train_scaled,y_train)
y_pred=lasso.predict(X_test_scaled)
mae=mean_absolute_error(y_test,y_pred)
score=r2_score(y_test,y_pred)
print("Mean absolute error", mae)
print("R2 Score", score)
plt.scatter(y_test,y_pred)

"""#**Cross validation Lasso**#"""

from sklearn.linear_model import LassoCV
lassocv=LassoCV(cv=5)
lassocv.fit(X_train_scaled,y_train)

y_pred=lassocv.predict(X_test_scaled)
plt.scatter(y_test,y_pred)
mae=mean_absolute_error(y_test,y_pred)
score=r2_score(y_test,y_pred)
print("Mean absolute error", mae)
print("R2 Score", score)

"""##**Ridge_Reg**##"""

from sklearn.linear_model import Ridge
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import r2_score
ridge=Ridge()
ridge.fit(X_train_scaled,y_train)
y_pred=ridge.predict(X_test_scaled)
mae=mean_absolute_error(y_test,y_pred)
score=r2_score(y_test,y_pred)
print("Mean absolute error", mae)
print("R2 Score", score)
plt.scatter(y_test,y_pred)

from sklearn.linear_model import RidgeCV
ridgecv=RidgeCV(cv=5)
ridgecv.fit(X_train_scaled,y_train)
y_pred=ridgecv.predict(X_test_scaled)
plt.scatter(y_test,y_pred)
mae=mean_absolute_error(y_test,y_pred)
score=r2_score(y_test,y_pred)
print("Mean absolute error", mae)
print("R2 Score", score)

ridgecv.get_params()

"""**ELASTIC_NET**"""

from sklearn.linear_model import ElasticNet
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import r2_score
elastic=ElasticNet()
elastic.fit(X_train_scaled,y_train)
y_pred=elastic.predict(X_test_scaled)
mae=mean_absolute_error(y_test,y_pred)
score=r2_score(y_test,y_pred)
print("Mean absolute error", mae)
print("R2 Score", score)
plt.scatter(y_test,y_pred)

from sklearn.linear_model import ElasticNetCV
elasticcv=ElasticNetCV(cv=5)
elasticcv.fit(X_train_scaled,y_train)
y_pred=elasticcv.predict(X_test_scaled)
plt.scatter(y_test,y_pred)
mae=mean_absolute_error(y_test,y_pred)
score=r2_score(y_test,y_pred)
print("Mean absolute error", mae)
print("R2 Score", score)

elasticcv.alphas_

"""##**PICKLING MODEL**"""

scaler

ridge

import pickle
pickle.dump(scaler,open("scaler.pkl","wb"))
pickle.dump(ridge,open("ridge.pkl","wb"))

